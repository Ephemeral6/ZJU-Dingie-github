import os
import shutil
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma

# ================= é…ç½®åŒºåŸŸ =================
DATA_SOURCE_PATH = "./knowledge_data" 
DB_PERSIST_PATH = "./chroma_db"
EMBEDDING_MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
# ===========================================

def build_database():
    if not os.path.exists(DATA_SOURCE_PATH):
        print(f"âŒ é”™è¯¯ï¼šç›®å½• {DATA_SOURCE_PATH} ä¸å­˜åœ¨ã€‚")
        return

    if os.path.exists(DB_PERSIST_PATH):
        print(f"ğŸ§¹ æ¸…ç†æ—§æ•°æ®åº“: {DB_PERSIST_PATH} ...")
        shutil.rmtree(DB_PERSIST_PATH)

    all_documents = []

    # 1. åŠ è½½ TXT æ–‡ä»¶
    print("ğŸ“‚ æ­£åœ¨åŠ è½½ .txt æ–‡ä»¶...")
    loader_txt = DirectoryLoader(
        DATA_SOURCE_PATH, 
        glob="**/*.txt", 
        loader_cls=TextLoader,
        loader_kwargs={"encoding": "utf-8", "autodetect_encoding": True}
    )
    docs_txt = loader_txt.load()
    all_documents.extend(docs_txt)
    print(f"   - æ‰¾åˆ° {len(docs_txt)} ä¸ª txt æ–‡æ¡£")

    # 2. åŠ è½½ Markdown æ–‡ä»¶ (æ–°å¢é€»è¾‘)
    print("ğŸ“‚ æ­£åœ¨åŠ è½½ .md æ–‡ä»¶...")
    loader_md = DirectoryLoader(
        DATA_SOURCE_PATH, 
        glob="**/*.md", 
        loader_cls=TextLoader, # TextLoader å®Œå…¨å¯ä»¥è¯»å– md çš„çº¯æ–‡æœ¬å†…å®¹
        loader_kwargs={"encoding": "utf-8", "autodetect_encoding": True}
    )
    docs_md = loader_md.load()
    all_documents.extend(docs_md)
    print(f"   - æ‰¾åˆ° {len(docs_md)} ä¸ª md æ–‡æ¡£")

    if not all_documents:
        print("âš ï¸ è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡æ¡£ã€‚")
        return

    # 3. æ™ºèƒ½åˆ‡åˆ† (é’ˆå¯¹ Markdown ä¼˜åŒ–)
    print("âœ‚ï¸ æ­£åœ¨åˆ‡åˆ†æ–‡æœ¬...")
    
    # æˆ‘ä»¬è°ƒæ•´äº†åˆ†éš”ç¬¦çš„ä¼˜å…ˆçº§ï¼š
    # ä¼˜å…ˆåœ¨ Markdown æ ‡é¢˜ (##, ###) å¤„åˆ‡æ–­ï¼Œ
    # å…¶æ¬¡åœ¨ æ¢è¡Œç¬¦+ã€ (é’ˆå¯¹ä¹‹å‰çš„è¯¾ç¨‹è¡¨) å¤„åˆ‡æ–­ï¼Œ
    # æœ€åæ‰æ˜¯æ™®é€šçš„æ¢è¡Œå’Œå¥å·ã€‚
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=150,
        separators=[
            "\n# ",   # <--- ğŸŸ¢ æ–°å¢è¿™ä¸ªï¼æœ€é«˜ä¼˜å…ˆçº§
            "\n## ", 
            "\n### ", 
            "\nã€", 
            "\n\n", 
            "\n", 
            "ã€‚", 
            "ï¼", 
            "ï¼Ÿ"
        ]
    )
    splits = text_splitter.split_documents(all_documents)
    print(f"âœ… æ‰€æœ‰æ–‡æ¡£å·²åˆ‡åˆ†ä¸º {len(splits)} ä¸ªçŸ¥è¯†å—ã€‚")

    # 4. åˆå§‹åŒ– Embedding
    print(f"ğŸ§  æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹...")
    embedding_function = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL_NAME,
        model_kwargs={'device': 'cpu'} 
    )

    # 5. å†™å…¥æ•°æ®åº“
    print("ğŸ’¾ æ­£åœ¨æ„å»ºå‘é‡æ•°æ®åº“...")
    vector_store = Chroma(
        collection_name="vtuber_knowledge",
        embedding_function=embedding_function,
        persist_directory=DB_PERSIST_PATH
    )
    
    batch_size = 100
    for i in range(0, len(splits), batch_size):
        batch = splits[i:i+batch_size]
        vector_store.add_documents(documents=batch)
        print(f"   å·²å¤„ç† {min(i+batch_size, len(splits))}/{len(splits)} ä¸ªå—...")

    print(f"ğŸ‰ çŸ¥è¯†åº“æ›´æ–°å®Œæ¯•ï¼æ”¯æŒ txt å’Œ mdã€‚")

if __name__ == "__main__":
    build_database()