from typing import List, Dict, Any, Optional
from loguru import logger
from .basic_memory_agent import BasicMemoryAgent
from ..input_types import BatchInput
import datetime
# å¼•å…¥ RAG ä¾èµ–
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma

class RAGAgent(BasicMemoryAgent):
    """
    å¸¦æœ‰ RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) åŠŸèƒ½çš„ Agentã€‚
    ç»§æ‰¿è‡ª BasicMemoryAgentï¼Œåœ¨æ„å»º Prompt é˜¶æ®µè‡ªåŠ¨æ£€ç´¢å‘é‡åº“å¹¶æ³¨å…¥ä¸Šä¸‹æ–‡ã€‚
    """

    def __init__(self, vector_db_path: str, *args, **kwargs):
        # 1. åˆå§‹åŒ–çˆ¶ç±» (BasicMemoryAgent)
        super().__init__(*args, **kwargs)
        
        # 2. åˆå§‹åŒ–å‘é‡æ£€ç´¢ç»„ä»¶
        logger.info(f"æ­£åœ¨åŠ è½½ RAG å‘é‡æ•°æ®åº“: {vector_db_path}")
        try:
            # å¿…é¡»å’Œ build_knowledge_base.py ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹
            self.embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                model_kwargs={'device': 'cpu'} # å¦‚æœæœ‰æ˜¾å¡æ”¹æˆ cuda
            )
            # åŠ è½½ç°æœ‰çš„æ•°æ®åº“
            self.vector_store = Chroma(
                persist_directory=vector_db_path, 
                embedding_function=self.embeddings,
                collection_name="vtuber_knowledge" # å¿…é¡»å’Œæ„å»ºæ—¶ä¸€è‡´
            )
            logger.info("RAG æ•°æ®åº“åŠ è½½æˆåŠŸï¼")
        except Exception as e:
            logger.error(f"RAG æ•°æ®åº“åŠ è½½å¤±è´¥ï¼ŒAgent å°†é€€åŒ–ä¸ºæ™®é€šæ¨¡å¼: {e}")
            self.vector_store = None
    
    def _retrieve_context(self, query: str, k: int = 3) -> str:
        """æ ¹æ®ç”¨æˆ·è¾“å…¥æ£€ç´¢ç›¸å…³çŸ¥è¯†ç‰‡æ®µ"""
        if not self.vector_store:
            return ""
            
        try:
            # æ£€ç´¢ç›¸ä¼¼åº¦æœ€é«˜çš„ k ä¸ªç‰‡æ®µ
            docs = self.vector_store.similarity_search(query, k=k)
            if not docs:
                return ""
            
            # æ‹¼æ¥ç‰‡æ®µå†…å®¹
            context_list = [f"èµ„æ–™{i+1}: {doc.page_content}" for i, doc in enumerate(docs)]
            return "\n\n".join(context_list)
        except Exception as e:
            logger.error(f"æ£€ç´¢å‡ºé”™: {e}")
            return ""

    def _to_messages(self, input_data: BatchInput) -> List[Dict[str, Any]]:
        """
        é‡å†™çˆ¶ç±»çš„æ¶ˆæ¯æ„å»ºæ–¹æ³•ã€‚
        åœ¨è¿”å›ç»™ LLM ä¹‹å‰ï¼Œæ‹¦æˆªç”¨æˆ·æ¶ˆæ¯å¹¶æ³¨å…¥ä¸Šä¸‹æ–‡å’Œå½“å‰æ—¶é—´ä¿¡æ¯ã€‚
        """
        import datetime  # å»ºè®®åœ¨æ–‡ä»¶å¤´éƒ¨å¯¼å…¥ï¼Œæˆ–è€…åœ¨è¿™é‡Œå±€éƒ¨å¯¼å…¥

        # 1. å…ˆè®©çˆ¶ç±»å¹²è‹¦åŠ›ï¼Œç”Ÿæˆæ ‡å‡†çš„æ¶ˆæ¯åˆ—è¡¨
        messages = super()._to_messages(input_data)
        
        # 2. æå–ç”¨æˆ·å½“å‰çš„æ–‡æœ¬è¾“å…¥ (ç”¨äºæ£€ç´¢)
        user_text = self._to_text_prompt(input_data)

        # 3. è·å–å½“å‰æ—¥æœŸä¿¡æ¯ (å…³é”®æ­¥éª¤ï¼šä¸ºè¯¾ç¨‹è¡¨æŸ¥è¯¢æä¾›æ—¶é—´åŸºå‡†)
        # æ ¼å¼ç¤ºä¾‹ï¼š2026å¹´03æœˆ02æ—¥ å‘¨ä¸€
        now = datetime.datetime.now()
        week_days = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"]
        date_info = f"{now.strftime('%Yå¹´%mæœˆ%dæ—¥')} {week_days[now.weekday()]}"
        
        # 4. å¦‚æœæœ‰æ–‡æœ¬ï¼Œå°±å¼€å§‹æ£€ç´¢
        if user_text and self.vector_store:
            logger.info(f"ğŸ” RAG æ­£åœ¨æ£€ç´¢: {user_text[:20]}...")
            context = self._retrieve_context(user_text)
            
            if context:
                logger.info(f"âœ… æ£€ç´¢åˆ° {len(context)} å­—ç¬¦çš„ä¸Šä¸‹æ–‡")
                
                # 5. æ‰¾åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­çš„æœ€åä¸€æ¡ (ä¹Ÿå°±æ˜¯ç”¨æˆ·åˆšåˆšè¯´çš„è¯)
                # messages ç»“æ„é€šå¸¸æ˜¯: [...å†å²å¯¹è¯..., {role: user, content: ...}]
                if messages and messages[-1]['role'] == 'user':
                    original_content = messages[-1]['content']
                    
                    # æ„é€ æ–°çš„ Promptï¼šåŒ…å«ç³»ç»Ÿæ—¶é—´ + ä¸Šä¸‹æ–‡ + ç”¨æˆ·åŸå§‹é—®é¢˜
                    # åŠ å…¥ã€ç³»ç»Ÿæ—¶é—´ã€‘æ˜¯ä¸ºäº†è®© LLM èƒ½æ¨ç®—å‡ºâ€œæ˜å¤©â€ã€â€œä¸‹å‘¨â€å…·ä½“æ˜¯å“ªä¸€å¤©ï¼Œä»è€ŒåŒ¹é…è¯¾ç¨‹è¡¨
                    augmented_content = (
                        f"ã€ç³»ç»Ÿæ—¶é—´ã€‘\nç°åœ¨æ˜¯ï¼š{date_info}\n\n"
                        f"ã€å‚è€ƒèµ„æ–™ã€‘\n{context}\n\n"
                        f"ã€ç”¨æˆ·é—®é¢˜ã€‘\n{user_text}\n\n"
                        f"è¯·ä¼˜å…ˆåŸºäºä¸Šè¿°å‚è€ƒèµ„æ–™å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å¦‚æœèµ„æ–™ä¸è¶³ï¼Œå†ä½¿ç”¨ä½ çš„é€šç”¨çŸ¥è¯†ã€‚"
                        f"å¯¹äºæ¶‰åŠç›¸å¯¹æ—¥æœŸçš„é—®é¢˜ï¼ˆå¦‚â€œæ˜å¤©â€ï¼‰ï¼Œè¯·åŠ¡å¿…æ ¹æ®ã€ç³»ç»Ÿæ—¶é—´ã€‘è¿›è¡Œæ¨ç®—ã€‚"
                    )
                    
                    # æ›¿æ¢æ‰åŸæœ‰çš„å†…å®¹
                    # æ³¨æ„ï¼šmessages[-1]['content'] å¯èƒ½æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨(å¤šæ¨¡æ€)æˆ–å­—ç¬¦ä¸²
                    if isinstance(original_content, str):
                        messages[-1]['content'] = augmented_content
                    elif isinstance(original_content, list):
                        # å¦‚æœæ˜¯å¤šæ¨¡æ€(æœ‰å›¾ç‰‡)ï¼Œæ‰¾åˆ° text éƒ¨åˆ†ä¿®æ”¹
                        for item in original_content:
                            if item.get('type') == 'text':
                                item['text'] = augmented_content
                                break
        
        return messages